{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T07:28:18.250508630Z",
     "start_time": "2023-06-27T07:28:18.234433853Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# define the global parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "clients = 15  # the total number of clients\n",
    "communicationRounds = 10  # the number of communications between the edges and the global model\n",
    "numOfEdges = 2 # the number of edge-aggregators\n",
    "edgeEpochs = 1 # the number of communications between an edge and its clients\n",
    "numEpochs = 5  # the number of local epochs on clients\n",
    "lr = 0.1  # training rate\n",
    "localBatchSize = 10  # batch size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T19:53:32.443739277Z",
     "start_time": "2023-06-27T19:53:32.437506563Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# load and process the MNIST data set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# download the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainData = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testData = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testLoader = torch.utils.data.DataLoader(testData, batch_size=10, shuffle=False)\n",
    "# perform a shuffle to ensure IID\n",
    "indices = list(range(len(trainData)))\n",
    "random.shuffle(indices)\n",
    "dataShuffled = [trainData[i] for i in indices]\n",
    "# calculating the size of the samples to ensure every client gets the same size\n",
    "subsetSize = len(trainData) // clients\n",
    "# create a subset for each client\n",
    "clientData = [dataShuffled[i * subsetSize:(i + 1) * subsetSize] for i in range(clients)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T19:53:38.451847435Z",
     "start_time": "2023-06-27T19:53:33.323829798Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# define the global model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "globalModel = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 64, kernel_size=3),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64 * 12 * 12, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T19:53:39.284790081Z",
     "start_time": "2023-06-27T19:53:39.275821686Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# define the edge-models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "edgeModels = []\n",
    "for _ in range(numOfEdges):\n",
    "    edgeModel = nn.Sequential(\n",
    "        nn.Conv2d(1, 32, kernel_size=3),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32, 64, kernel_size=3),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(64 * 12 * 12, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 10)\n",
    "    )\n",
    "    edgeModels.append(edgeModel)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T19:53:40.228996494Z",
     "start_time": "2023-06-27T19:53:40.180516844Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud Communication Round: 1\n",
      "Edge Communication Round: 1 on edge 1\n",
      "Client 1 belonging to edge 1, finished training for: 5 epoch(s)\n",
      "Client 2 belonging to edge 1, finished training for: 5 epoch(s)\n",
      "Client 3 belonging to edge 1, finished training for: 5 epoch(s)\n",
      "Client 4 belonging to edge 1, finished training for: 5 epoch(s)\n",
      "Client 5 belonging to edge 1, finished training for: 5 epoch(s)\n",
      "Client 6 belonging to edge 1, finished training for: 5 epoch(s)\n",
      "Client 7 belonging to edge 1, finished training for: 5 epoch(s)\n",
      "Edge Communication Round: 1 on edge 2\n",
      "Client 8 belonging to edge 2, finished training for: 5 epoch(s)\n",
      "Client 9 belonging to edge 2, finished training for: 5 epoch(s)\n",
      "Client 10 belonging to edge 2, finished training for: 5 epoch(s)\n",
      "Client 11 belonging to edge 2, finished training for: 5 epoch(s)\n",
      "Client 12 belonging to edge 2, finished training for: 5 epoch(s)\n",
      "Client 13 belonging to edge 2, finished training for: 5 epoch(s)\n",
      "Client 14 belonging to edge 2, finished training for: 5 epoch(s)\n",
      "Cloud Communication Round: 2\n",
      "Edge Communication Round: 1 on edge 1\n",
      "Client 1 belonging to edge 1, finished training for: 5 epoch(s)\n",
      "Client 2 belonging to edge 1, finished training for: 5 epoch(s)\n",
      "Client 3 belonging to edge 1, finished training for: 5 epoch(s)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[56], line 33\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m inputs, labels \u001B[38;5;129;01min\u001B[39;00m trainLoader:\n\u001B[1;32m     32\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 33\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mclientModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     34\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[1;32m     35\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    203\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 204\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    205\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 463\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    457\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    458\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "# iterate over all rounds\n",
    "for rnd in range(communicationRounds):\n",
    "    # print round number\n",
    "    print(f\"Cloud Communication Round: {rnd + 1}\")\n",
    "    # to save edges parameters\n",
    "    params = []\n",
    "    # iterate over all edge models\n",
    "    for i, edgeModel in enumerate(edgeModels):\n",
    "        # calculate the start and end indices of the clients on the current edge\n",
    "        startClient = (i * (clients // numOfEdges))\n",
    "        endClient = ((i + 1) * (clients // numOfEdges))\n",
    "        # select clients for the current edge\n",
    "        selectedClients = list(range(startClient, endClient))\n",
    "        # to save local clients models parameters within the current edge\n",
    "        edgeParams = []\n",
    "        # iterate over selected clients on the current edge\n",
    "        for edgeRound in range(edgeEpochs):\n",
    "            print(f\"Edge Communication Round: {edgeRound + 1} on edge {i+1}\")\n",
    "            for client in selectedClients:\n",
    "                # local model\n",
    "                clientModel = nn.Sequential(*edgeModel)\n",
    "                # load the data to the model\n",
    "                trainLoader = data.DataLoader(clientData[client], batch_size=localBatchSize, shuffle=False)\n",
    "                # client optimizer and loss function\n",
    "                criterion = nn.CrossEntropyLoss()\n",
    "                optimizer = optim.SGD(clientModel.parameters(), lr=lr)\n",
    "                # train model on client k for the defined local epochs\n",
    "                for epoch in range(numEpochs):\n",
    "                    # perform forward pass and backpropagation, updating the local model\n",
    "                    for inputs, labels in trainLoader:\n",
    "                        optimizer.zero_grad()\n",
    "                        outputs = clientModel(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                # print client's k training progress\n",
    "                print(f\"Client {client + 1} belonging to edge {i + 1}, finished training for: {numEpochs} epoch(s)\")\n",
    "                # aggregate local models parameters of the clients of the current edge\n",
    "                local_params = [param.data for param in clientModel.parameters()]\n",
    "                edgeParams.append(local_params)\n",
    "        # average the parameters from all local models within the current edge\n",
    "        averagedParameters = [\n",
    "            torch.mean(torch.stack(params), dim=0) for params in zip(*edgeParams)\n",
    "        ]\n",
    "        # update the model on the current edge\n",
    "        for edgeParam, avgParam in zip(edgeModel.parameters(), averagedParameters):\n",
    "            edgeParam.data = avgParam\n",
    "    # aggregate all edge models\n",
    "    averagedParameters = [\n",
    "        torch.mean(torch.stack(params), dim=0) for params in zip(*(edgeModel.parameters() for edgeModel in edgeModels))\n",
    "    ]\n",
    "    # update the global model parameters\n",
    "    for globalParam, avgParam in zip(globalModel.parameters(), averagedParameters):\n",
    "        globalParam.data = avgParam\n",
    "    # send the global model parameters back to the edges for the next communication round\n",
    "    for edgeModel in edgeModels:\n",
    "        edgeModel.load_state_dict(globalModel.state_dict())\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testLoader:\n",
    "            outputs = globalModel(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(f\"Training is finished after {communicationRounds} communication rounds on a total of {clients} clients clustered across {numOfEdges} edges!\")\n",
    "\n",
    "# Plot the evolution of global model accuracy\n",
    "plt.plot(range(1, communicationRounds + 1), accuracies)\n",
    "plt.xlabel(\"Communication Round\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Evolution of Global Model Accuracy\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T19:58:23.274056798Z",
     "start_time": "2023-06-27T19:53:41.596383562Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# testing data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.18%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in testLoader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = globalModel(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-27T19:36:13.474815369Z",
     "start_time": "2023-06-27T19:36:10.471721783Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
